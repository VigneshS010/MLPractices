{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNUmUZURoTyLPD+uN2OrHr/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import Libraries"],"metadata":{"id":"_koUN7SZg1kC"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"9UAgQLS9e2um","executionInfo":{"status":"ok","timestamp":1720630465804,"user_tz":-330,"elapsed":1500,"user":{"displayName":"Vignesh S","userId":"03378886263089425882"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["Imorting the Dataset"],"metadata":{"id":"9NxCCwI_hT0E"}},{"cell_type":"code","source":["dataset = pd.read_csv('Data.csv')\n","\n","# Features\n","# [Row , column]\n","X = dataset.iloc[:, :-1].values\n","\n","# Dependent variable vector\n","# the values convert to numpy array\n","y = dataset.iloc[:,-1].values\n","\n","\n","print(X)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASCbjprWhXdS","executionInfo":{"status":"ok","timestamp":1720630465804,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vignesh S","userId":"03378886263089425882"}},"outputId":"3dd7c611-57db-4697-ee79-1f3c9b2afb4e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n","['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"]}]},{"cell_type":"markdown","source":["Taking care of missing data"],"metadata":{"id":"LBKvzYPMk_5x"}},{"cell_type":"code","source":["# Replacing the missing data with average of that column\n","\n","# We use scikit learn all this course , here also it uses\n","\n","from sklearn.impute import SimpleImputer\n","\n","#Simple Imputer\n","imputer = SimpleImputer(missing_values =np.nan ,strategy='mean')\n","imputer.fit(X[:,1:3])\n","# transform gives new updated list seperately\n","X[:,1:3] = imputer.transform(X[:,1:3])\n","\n","print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xLc93rkwkYGw","executionInfo":{"status":"ok","timestamp":1720630467010,"user_tz":-330,"elapsed":1209,"user":{"displayName":"Vignesh S","userId":"03378886263089425882"}},"outputId":"2aa941fb-baf0-422a-9b13-c2a3b610f2bb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","source":["Encoding categorical data"],"metadata":{"id":"4shhZH_lo5-c"}},{"cell_type":"code","source":["# Converting String into numbers\n","# One hot encoding is used (most famous)\n","\n","# Column transform from scikit learn\n","from sklearn.compose import ColumnTransformer\n","\n","# One hot encoding class\n","from sklearn.preprocessing import OneHotEncoder\n","\n","#object\n","# transformer => what we need to do - endcode\n","# What type of encoding - onehot encoding\n","# Which column - [0]\n","# remainder => if we wont use , that only encode 3 columns only\n","ct = ColumnTransformer(transformers= [('encoder',OneHotEncoder(),[0])],remainder='passthrough')\n","\n","X = np.array(ct.fit_transform(X))\n","\n","print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vYtgUyPUo5cy","executionInfo":{"status":"ok","timestamp":1720630467010,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vignesh S","userId":"03378886263089425882"}},"outputId":"c78a1cdd-3cec-45a3-e67e-8d8076903571"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","source":["Encoding Dependent variable"],"metadata":{"id":"RDGQ_cxFr4in"}},{"cell_type":"code","source":["# COnverting yes, no to 0s and 1s\n","\n","from sklearn.preprocessing import LabelEncoder\n","#object\n","le = LabelEncoder()\n","y = le.fit_transform(y)\n","\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NdTm5DAFpVgo","executionInfo":{"status":"ok","timestamp":1720630467010,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vignesh S","userId":"03378886263089425882"}},"outputId":"5092c345-5354-4a3f-fb53-68c15ea081c3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1 0 1]\n"]}]},{"cell_type":"markdown","source":["Split Training set and Test set"],"metadata":{"id":"cXKawIcyO9Dm"}},{"cell_type":"code","source":["# This splitting must before the feature scaling\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n","\n","# The random state used to map the same x train, y train and x test y test\n","print(X_train)\n","print(X_test)\n","print(y_train)\n","print(y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-A1oVhQO5ZT","executionInfo":{"status":"ok","timestamp":1720630467010,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vignesh S","userId":"03378886263089425882"}},"outputId":"868a2b6a-c650-46df-ba66-40b5bf6315e9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 35.0 58000.0]]\n","[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n","[0 1 0 0 1 1 0 1]\n","[0 1]\n"]}]},{"cell_type":"markdown","source":["Feature Scaling"],"metadata":{"id":"JePoXphWPGRM"}},{"cell_type":"code","source":["# Always the feature scaling must be  after splitting train and test set\n","\n","# Because feature scaling takes means ans other stuff in the data\n","# If we use feature scaling before , it some info leakage of the test set also\n","# So it  is not a good  way , so use after splitting\n","\n","\n","# Here we  use sttandardization -3 to 3\n","# there is no necessary to apply sc for dummy values (Contries)  because it already in that  range\n","\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","sc = StandardScaler()\n","\n","X_train[:, 3:] = sc.fit_transform(X_train[:, 3:] )\n","X_test[:, 3:] = sc.transform(X_test[:, 3:] )\n","\n","# on test data , only transform is used , because it used the fit data from the  train data , we want that (google it why)\n","\n","print(X_train)\n","print()\n","print(X_test)"],"metadata":{"id":"K639Cbh9PFfl","executionInfo":{"status":"ok","timestamp":1720630486761,"user_tz":-330,"elapsed":1023,"user":{"displayName":"Vignesh S","userId":"03378886263089425882"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3f2fbf34-8a83-479c-895c-2dc4b7344772"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 -0.1915918438457856 -1.0781259408412427]\n"," [0.0 1.0 0.0 -0.014117293757057902 -0.07013167641635401]\n"," [1.0 0.0 0.0 0.5667085065333239 0.6335624327104546]\n"," [0.0 0.0 1.0 -0.3045301939022488 -0.30786617274297895]\n"," [0.0 0.0 1.0 -1.901801144700799 -1.4204636155515822]\n"," [1.0 0.0 0.0 1.1475343068237056 1.2326533634535488]\n"," [0.0 1.0 0.0 1.4379472069688966 1.5749910381638883]\n"," [1.0 0.0 0.0 -0.7401495441200352 -0.5646194287757336]]\n","\n","[[0.0 1.0 0.0 -1.4661817944830127 -0.9069571034860731]\n"," [1.0 0.0 0.0 -0.44973664397484425 0.20564033932253029]]\n"]}]}]}